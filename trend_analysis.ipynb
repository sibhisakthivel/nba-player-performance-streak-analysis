{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e925a0f0",
   "metadata": {},
   "source": [
    "# NBA Player Performance Trend Analysis\n",
    "**By Sibhi Sakthivel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428c52d4",
   "metadata": {},
   "source": [
    "# 1) Introduction\n",
    "\n",
    "Even the best athletes in the world have an off night eventually, sometimes even a few bad games in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b943f",
   "metadata": {},
   "source": [
    "# 2) Research Question\n",
    "\n",
    "In this study, we are going to be designing, executing, and sharing my findings on trends in NBA player scoring performances. Specifically, we are going to be addressing the question:\n",
    "\n",
    "**Do sustained departures from a player’s long-term scoring expectation correlate with an increased likelihood of subsequent over- or under-performance relative to that expectation?**\n",
    "\n",
    "In other words, we are analyzing whether a period of consecutive games with poor scoring performances is correlated with a higher chance of an upcoming game exceeding baseline scoring performance, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f2cce",
   "metadata": {},
   "source": [
    "# 3) Context, Assumptions, and Confounding Factors\n",
    "\n",
    "NBA player performance is influenced by several factors, including opponent matchup and teammate availability. These two factors can have a significant impact on a player's efficiency, usage, and minutes played, which can influence how well a player plays and the statistics they record.\n",
    "\n",
    "Because opponent strength and lineup composition are not randomly assigned, they represent potential confounding variables when analyzing short-term performance trends. Apparent performance “reversion” or “continuation” may reflect changes in these factors rather than intrinsic performance dynamics. For this reason, the analysis proceeds in stages. Initial results examine the raw relationship between sustained performance deviations and subsequent outcomes, followed by conditioned analyses that explicitly account for matchup difficulty and teammate availability to assess robustness.\n",
    "\n",
    "This analysis is observational and does not attempt to establish causal effects. Instead, it aims to evaluate whether commonly cited performance narratives retain predictive or descriptive value once key contextual factors are considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca5a98",
   "metadata": {},
   "source": [
    "# 3) Data Overview\n",
    "\n",
    "### Unit of Analysis\n",
    "\n",
    "The primary unit of analysis in this study is a player–game observation, where each row represents an individual player’s scoring performance in a single NBA game.\n",
    "\n",
    "### Data Source\n",
    "\n",
    "The dataset was constructed from the publicly available NBA API, in which we retrieved game-level data including player box score statistics, game context variables, teammate availability, and opponent matchup metrics.\n",
    "\n",
    "### Data Scope\n",
    "\n",
    "The analysis focuses on regular-season games from the 2024–25 NBA season, with players required to meet minimum participation thresholds to ensure stable baseline estimates.\n",
    "\n",
    "For clarity and interpretability, this study focuses exclusively on player scoring performance, measured using points scored per game. While player performance is multi-dimensional, scoring provides a clear, widely understood outcome that aligns with common performance narratives and decision-making contexts.\n",
    "\n",
    "Additionally, the analysis is conducted at the individual player level, using a single high-usage player as a case study. This design choice allows for detailed examination of performance dynamics without conflating effects across heterogeneous player roles, play styles, and usage profiles.\n",
    "\n",
    "While this limits the generalizability of results, the framework is designed to be extensible to additional players and performance metrics in future work.\n",
    "\n",
    "### Data Limitations\n",
    "\n",
    "Several limitations are inherent in the dataset. Defensive matchup difficulty is represented using team-level and positional defensive metrics, which serve as coarse proxies and do not capture individual on-ball defensive assignments or in-game matchup adjustments.\n",
    "\n",
    "Teammate availability is approximated using minutes-based thresholds, where high-usage teammates are considered “available” if they play at least a fixed proportion of their season-average minutes. While this approach captures major role-level changes, it may not fully reflect partial usage restrictions, staggered rotations, or in-game context that affects effective player involvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b10e4de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_id_api', 'team_id', 'team_city', 'team_name', 'team_tricode',\n",
      "       'team_slug', 'player_id', 'first_name', 'family_name', 'name_initial',\n",
      "       'player_slug', 'position', 'comment', 'jersey_number', 'minutes',\n",
      "       'field_goals_made', 'field_goals_attempted', 'field_goals_percentage',\n",
      "       'three_pointers_made', 'three_pointers_attempted',\n",
      "       'three_pointers_percentage', 'free_throws_made',\n",
      "       'free_throws_attempted', 'free_throws_percentage', 'rebounds_offensive',\n",
      "       'rebounds_defensive', 'rebounds_total', 'assists', 'steals', 'blocks',\n",
      "       'turnovers', 'fouls_personal', 'points', 'plus_minus_points',\n",
      "       'game_id'],\n",
      "      dtype='object') Index(['season_id', 'team_id', 'team_abbreviation', 'team_name', 'game_id',\n",
      "       'game_date', 'matchup', 'wl', 'minutes', 'field_goals_made',\n",
      "       'field_goals_attempted', 'field_goals_percentage',\n",
      "       'three_pointers_made', 'three_pointers_attempted',\n",
      "       'three_pointers_percentage', 'free_throws_made',\n",
      "       'free_throws_attempted', 'free_throws_percentage', 'rebounds_offensive',\n",
      "       'rebounds_defensive', 'rebounds_total', 'assists', 'steals', 'blocks',\n",
      "       'turnovers', 'fouls_personal', 'points', 'plus_minus',\n",
      "       'video_available', 'season', 'season_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Connect to database\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "DB_USER = \"admin\"\n",
    "DB_PASSWORD = \"admin\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = 5433\n",
    "DB_NAME = \"nba_db\"\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    ")\n",
    "\n",
    "# Player box score data\n",
    "pbs = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM boxscores.player_boxscores_traditional_v3\n",
    "    \"\"\",\n",
    "    engine\n",
    ")\n",
    "\n",
    "# Team box score data\n",
    "tbs = pd.read_sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM boxscores.league_gamelogs\n",
    "    \"\"\",\n",
    "    engine\n",
    ")\n",
    "\n",
    "print(pbs.columns, tbs.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5663128",
   "metadata": {},
   "source": [
    "# 4) Methodology\n",
    "\n",
    "### Baseline Scoring Performance\n",
    "\n",
    "A player’s baseline scoring performance is defined as their season-average points per game across all regular-season games played up to a given point in the season. This baseline is intended to represent a player’s long-term expected scoring output under typical conditions, abstracting away short-term variance and game-to-game noise.\n",
    "\n",
    "By anchoring performance deviations to a long-term expectation, the analysis focuses on whether sustained departures from expected scoring levels are associated with short-term reversion or continuation in subsequent games.\n",
    "\n",
    "Rolling-window baselines were considered but not used in order to avoid conflating short-term form with long-term expectation, which is central to the research question.\n",
    "\n",
    "### Performance Deviation\n",
    "\n",
    "For each game, a player’s performance deviation is defined as the difference between their observed scoring output in that game and their season-average scoring baseline. This deviation represents how much a player over- or under-performed relative to their long-term expected scoring level.\n",
    "\n",
    "Positive deviations indicate games in which the player scored more points than their season average, while negative deviations indicate games in which the player scored fewer points than expected. By preserving the direction of the deviation, this definition allows performance to be evaluated not only in terms of magnitude but also in terms of whether a player exceeded or fell short of their baseline expectation.\n",
    "\n",
    "This measure serves as the fundamental building block for identifying sustained periods of over- or under-performance across consecutive games, which are examined in subsequent sections.\n",
    "\n",
    "### Sustained Performance Streaks\n",
    "\n",
    "Each game is first classified as an overperformance or underperformance based on whether the player’s scoring output exceeds or falls below their season-average baseline. Using this classification, a sustained performance streak is defined as a sequence of consecutive games in which the player consistently overperforms or underperforms relative to baseline.\n",
    "\n",
    "In this study, a streak is considered to occur when a player records at least three consecutive overperforming or underperforming games. The length of the streak corresponds to the number of consecutive games meeting this criterion. This framework allows performance trends to be represented as discrete states that can be used to evaluate how the likelihood of subsequent over- or underperformance changes as streak length increases.\n",
    "\n",
    "### Outcome Definition\n",
    "\n",
    "The primary outcome of interest is the player’s scoring performance in the game immediately following a sustained performance streak. For each identified streak, the subsequent game is classified based on whether the player’s scoring output exceeds or falls below their season-average baseline.\n",
    "\n",
    "This outcome is represented as a binary indicator, where an overperformance corresponds to scoring above baseline and an underperformance corresponds to scoring below baseline. This formulation allows the probability of over- or underperformance in the next game to be estimated conditional on the length and direction of the preceding streak.\n",
    "\n",
    "### Contextual Adjustments\n",
    "\n",
    "Opponent difficulty is represented using team-level defensive metrics, which serve as coarse proxies for overall matchup strength. These measures are used to stratify analyses and assess whether observed performance relationships persist across varying levels of opponent defensive quality.\n",
    "\n",
    "Teammate availability is approximated using minutes-based thresholds. High-usage teammates are considered available in a given game if they play at least a fixed proportion of their season-average minutes. This approach is intended to capture major role-level shifts while remaining interpretable and reproducible.\n",
    "\n",
    "These contextual variables are not used to redefine performance baselines or streaks, but are incorporated in subsequent analyses to evaluate whether observed performance patterns are robust to changes in game context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbfd35",
   "metadata": {},
   "source": [
    "# 5) Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ec6b0",
   "metadata": {},
   "source": [
    "### Dataset Construction\n",
    "\n",
    "We'll begin by constructing a dataset from the database that include all the data types we'll be using in this analysis. These data types include:\n",
    "- Game date/ID\n",
    "- Player name/ID\n",
    "- Team name/ID\n",
    "- Player points scored\n",
    "- Player season average points\n",
    "- Player point deviation from season average\n",
    "- Scoring performance over/under season average flag\n",
    "\n",
    "The final game of the season is excluded from conditional probability calculations since no subsequent outcome exists.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8166e0a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.UndefinedColumn) column \"TEAM_ID\" does not exist\nLINE 4:         \"TEAM_ID\" AS team_id, \n                ^\n\n[SQL: \nWITH teams AS(\n    SELECT \n        \"TEAM_ID\" AS team_id, \n        \"TEAM_ABBREVIATION\" AS team, \n        \"GAME_ID\" AS game_id,\n        \"GAME_DATE\" AS game_date, \n        \"MATCHUP\" AS matchup, \n        \"PTS\" AS pts,\n        AVG(\"PTS\") OVER (\n            PARTITION BY RIGHT(\"MATCHUP\", 3)\n            ORDER BY \"GAME_DATE\" ASC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n        ) AS opp_pts_allowed\n    FROM boxscores.league_gamelogs t\n)\n\nSELECT \n    t.game_id,\n    t.game_date,\n    p.\"personId\" AS player_id,\n    CONCAT_WS(' ', p.\"firstName\", p.\"familyName\") AS player_name,\n    p.\"teamId\" AS team_id,\n    RIGHT(t.matchup, 3) AS team,\n    p.points AS pts,\n    AVG(p.points) OVER(\n        PARTITION BY  p.\"personId\"\n        ORDER BY t.game_date ASC\n        ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n    ) AS szn_avg_pts,\n    p.points\n        - AVG(p.points) OVER( \n            PARTITION BY  p.\"personId\"\n            ORDER BY t.game_date ASC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n        ) AS deviation,\n    CASE\n        WHEN p.points\n           > AVG(p.points) OVER (\n                 PARTITION BY p.\"personId\"\n                 ORDER BY t.game_date ASC\n                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n             )\n        THEN 1\n        ELSE 0\n    END AS over_flag,\n    LEFT(t.matchup, 3) AS opp,\n    t.opp_pts_allowed\nFROM teams t\nJOIN boxscores.player_boxscores_traditional_v3 p\n    ON p.\"teamId\" <> t.team_id\n        AND p.\"gameId\" = t.game_id\nORDER BY player_id, game_date ASC\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUndefinedColumn\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1967\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:952\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m952\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUndefinedColumn\u001b[39m: column \"TEAM_ID\" does not exist\nLINE 4:         \"TEAM_ID\" AS team_id, \n                ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m      1\u001b[39m dataset = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33mWITH teams AS(\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33m    SELECT \u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     53\u001b[39m \u001b[33mORDER BY player_id, game_date ASC\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m analysis_dataset = data[data[\u001b[33m\"\u001b[39m\u001b[33mplayer_name\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mJamal Murray\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     58\u001b[39m analysis_dataset.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/pandas/io/sql.py:736\u001b[39m, in \u001b[36mread_sql\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[39m\n\u001b[32m    726\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql.read_table(\n\u001b[32m    727\u001b[39m         sql,\n\u001b[32m    728\u001b[39m         index_col=index_col,\n\u001b[32m   (...)\u001b[39m\u001b[32m    733\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m    734\u001b[39m     )\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    741\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/pandas/io/sql.py:1848\u001b[39m, in \u001b[36mSQLDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   1791\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   1792\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1793\u001b[39m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1800\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1801\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m   1802\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[33;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[32m   1804\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1846\u001b[39m \n\u001b[32m   1847\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1848\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1849\u001b[39m     columns = result.keys()\n\u001b[32m   1851\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/pandas/io/sql.py:1671\u001b[39m, in \u001b[36mSQLDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   1669\u001b[39m args = [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[32m   1670\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1671\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1672\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.con.execute(sql, *args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1779\u001b[39m, in \u001b[36mConnection.exec_driver_sql\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1774\u001b[39m execution_options = \u001b[38;5;28mself\u001b[39m._execution_options.merge_with(\n\u001b[32m   1775\u001b[39m     execution_options\n\u001b[32m   1776\u001b[39m )\n\u001b[32m   1778\u001b[39m dialect = \u001b[38;5;28mself\u001b[39m.dialect\n\u001b[32m-> \u001b[39m\u001b[32m1779\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1846\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1844\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1845\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1986\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1983\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2363\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2361\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2362\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2364\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2365\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1967\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1965\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1972\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1973\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1974\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1978\u001b[39m         context.executemany,\n\u001b[32m   1979\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/nba-performance-trend-analysis/.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:952\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m952\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mProgrammingError\u001b[39m: (psycopg2.errors.UndefinedColumn) column \"TEAM_ID\" does not exist\nLINE 4:         \"TEAM_ID\" AS team_id, \n                ^\n\n[SQL: \nWITH teams AS(\n    SELECT \n        \"TEAM_ID\" AS team_id, \n        \"TEAM_ABBREVIATION\" AS team, \n        \"GAME_ID\" AS game_id,\n        \"GAME_DATE\" AS game_date, \n        \"MATCHUP\" AS matchup, \n        \"PTS\" AS pts,\n        AVG(\"PTS\") OVER (\n            PARTITION BY RIGHT(\"MATCHUP\", 3)\n            ORDER BY \"GAME_DATE\" ASC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n        ) AS opp_pts_allowed\n    FROM boxscores.league_gamelogs t\n)\n\nSELECT \n    t.game_id,\n    t.game_date,\n    p.\"personId\" AS player_id,\n    CONCAT_WS(' ', p.\"firstName\", p.\"familyName\") AS player_name,\n    p.\"teamId\" AS team_id,\n    RIGHT(t.matchup, 3) AS team,\n    p.points AS pts,\n    AVG(p.points) OVER(\n        PARTITION BY  p.\"personId\"\n        ORDER BY t.game_date ASC\n        ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n    ) AS szn_avg_pts,\n    p.points\n        - AVG(p.points) OVER( \n            PARTITION BY  p.\"personId\"\n            ORDER BY t.game_date ASC\n            ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n        ) AS deviation,\n    CASE\n        WHEN p.points\n           > AVG(p.points) OVER (\n                 PARTITION BY p.\"personId\"\n                 ORDER BY t.game_date ASC\n                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n             )\n        THEN 1\n        ELSE 0\n    END AS over_flag,\n    LEFT(t.matchup, 3) AS opp,\n    t.opp_pts_allowed\nFROM teams t\nJOIN boxscores.player_boxscores_traditional_v3 p\n    ON p.\"teamId\" <> t.team_id\n        AND p.\"gameId\" = t.game_id\nORDER BY player_id, game_date ASC\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "dataset = \"\"\"\n",
    "WITH teams AS(\n",
    "    SELECT \n",
    "        \"TEAM_ID\" AS team_id, \n",
    "        \"TEAM_ABBREVIATION\" AS team, \n",
    "        \"GAME_ID\" AS game_id,\n",
    "        \"GAME_DATE\" AS game_date, \n",
    "        \"MATCHUP\" AS matchup, \n",
    "        \"PTS\" AS pts,\n",
    "        AVG(\"PTS\") OVER (\n",
    "            PARTITION BY RIGHT(\"MATCHUP\", 3)\n",
    "            ORDER BY \"GAME_DATE\" ASC\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "        ) AS opp_pts_allowed\n",
    "    FROM boxscores.league_gamelogs t\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    t.game_id,\n",
    "    t.game_date,\n",
    "    p.\"personId\" AS player_id,\n",
    "    CONCAT_WS(' ', p.\"firstName\", p.\"familyName\") AS player_name,\n",
    "    p.\"teamId\" AS team_id,\n",
    "    RIGHT(t.matchup, 3) AS team,\n",
    "    p.points AS pts,\n",
    "    AVG(p.points) OVER(\n",
    "        PARTITION BY  p.\"personId\"\n",
    "        ORDER BY t.game_date ASC\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "    ) AS szn_avg_pts,\n",
    "    p.points\n",
    "        - AVG(p.points) OVER( \n",
    "            PARTITION BY  p.\"personId\"\n",
    "            ORDER BY t.game_date ASC\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "        ) AS deviation,\n",
    "    CASE\n",
    "        WHEN p.points\n",
    "           > AVG(p.points) OVER (\n",
    "                 PARTITION BY p.\"personId\"\n",
    "                 ORDER BY t.game_date ASC\n",
    "                 ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "             )\n",
    "        THEN 1\n",
    "        ELSE 0\n",
    "    END AS over_flag,\n",
    "    LEFT(t.matchup, 3) AS opp,\n",
    "    t.opp_pts_allowed\n",
    "FROM teams t\n",
    "JOIN boxscores.player_boxscores_traditional_v3 p\n",
    "    ON p.\"teamId\" <> t.team_id\n",
    "        AND p.\"gameId\" = t.game_id\n",
    "ORDER BY player_id, game_date ASC\n",
    "\"\"\"\n",
    "\n",
    "data = pd.read_sql(dataset, engine)\n",
    "analysis_dataset = data[data[\"player_name\"] == \"Jamal Murray\"]\n",
    "analysis_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d1e94",
   "metadata": {},
   "source": [
    "### Feature Validation & Sanity Checks\n",
    "\n",
    "Now we'll perform some checks to verify that variables are logical and correctly represent what they are intended to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis_dataset.shape)       # number of games played, number of cols in df\n",
    "print(analysis_dataset.groupby(     # number of player_id - game_id combos = number of games played\n",
    "    [\"player_id\", \"game_id\"]).size().value_counts()) \n",
    "\n",
    "print(analysis_dataset[\"game_date\"].is_monotonic_increasing)                # game dates are ordered correctly\n",
    "print(analysis_dataset.head(3)[[\"pts\", \"szn_avg_pts\", \"opp_pts_allowed\"]])  # first row has point averages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "analysis_dataset[[\"game_date\", \"szn_avg_pts\"]].plot(\n",
    "    x=\"game_date\",\n",
    "    y=\"szn_avg_pts\",\n",
    "    title=\"Season Average Points Over Time\"\n",
    ")\n",
    "\n",
    "analysis_dataset[\"deviation\"].describe()    # mean is about 0, \n",
    "\n",
    "print(analysis_dataset.sample(3)[[\"game_date\", \"pts\", \"szn_avg_pts\", \"deviation\"]]) # deviation correctly calculated\n",
    "\n",
    "print((\n",
    "    (analysis_dataset[\"pts\"] > analysis_dataset[\"szn_avg_pts\"])\n",
    "    == (analysis_dataset[\"over_flag\"] == 1)\n",
    ").value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82221fc",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "First let's observe the distribution of deviations throughout the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(analysis_dataset[\"game_date\"], analysis_dataset[\"deviation\"])\n",
    "plt.axhline(0)\n",
    "plt.title(\"Point Deviation from Season Baseline Over Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965152ad",
   "metadata": {},
   "source": [
    "Now let's look into how the season average points scored changes throughout the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42706d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure data is sorted correctly\n",
    "analysis_dataset = analysis_dataset.sort_values(\"game_date\")\n",
    "\n",
    "# Rolling average (10-game)\n",
    "analysis_dataset[\"rolling_10_pts\"] = (\n",
    "    analysis_dataset[\"pts\"]\n",
    "    .rolling(window=10, min_periods=3)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Season cumulative average\n",
    "plt.plot(\n",
    "    analysis_dataset[\"game_date\"],\n",
    "    analysis_dataset[\"szn_avg_pts\"],\n",
    "    label=\"Season Avg Points\",\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Rolling 10-game average\n",
    "plt.plot(\n",
    "    analysis_dataset[\"game_date\"],\n",
    "    analysis_dataset[\"rolling_10_pts\"],\n",
    "    label=\"Rolling 10-Game Avg\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\"\n",
    ")\n",
    "\n",
    "# Actual game points\n",
    "plt.scatter(\n",
    "    analysis_dataset[\"game_date\"],\n",
    "    analysis_dataset[\"pts\"],\n",
    "    label=\"Game Points\",\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Formatting\n",
    "plt.ylim(15, 30)\n",
    "plt.xlabel(\"Game Date\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.title(\"Points Scored vs Season & Rolling Averages Over Time\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early = analysis_dataset.head(15)[\"pts\"].mean()\n",
    "late = analysis_dataset.tail(15)[\"pts\"].mean()\n",
    "\n",
    "early, late\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a496a",
   "metadata": {},
   "source": [
    "Now let's take a look at lengths of streaks where scoring is either over or under the season average points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd95e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Compute Over / Under Performance Streaks\n",
    "# ============================================\n",
    "\n",
    "# Ensure data is ordered correctly\n",
    "analysis_dataset = (\n",
    "    analysis_dataset\n",
    "    .sort_values(\"game_date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 1: Identify where a streak changes\n",
    "# A new streak starts whenever over_flag\n",
    "# differs from the previous game\n",
    "# --------------------------------------------\n",
    "analysis_dataset[\"streak_id\"] = (\n",
    "    analysis_dataset[\"over_flag\"]\n",
    "    .ne(analysis_dataset[\"over_flag\"].shift())\n",
    "    .cumsum()\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 2: Compute streak length within each run\n",
    "# cumcount() gives 0,1,2,... so we add 1\n",
    "# --------------------------------------------\n",
    "analysis_dataset[\"streak_length\"] = (\n",
    "    analysis_dataset\n",
    "    .groupby(\"streak_id\")\n",
    "    .cumcount()\n",
    "    .add(1)\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 3: Signed streaks (optional but useful)\n",
    "# Positive = over-performance streak\n",
    "# Negative = under-performance streak\n",
    "# --------------------------------------------\n",
    "analysis_dataset[\"signed_streak\"] = (\n",
    "    analysis_dataset[\"streak_length\"]\n",
    "    * analysis_dataset[\"over_flag\"].replace({0: -1})\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Sanity check: inspect early rows\n",
    "# --------------------------------------------\n",
    "analysis_dataset[\n",
    "    [\"game_date\", \"pts\", \"szn_avg_pts\", \"over_flag\", \"streak_length\", \"signed_streak\"]\n",
    "].head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Compute Next-Game Outcome & Conditional Probabilities\n",
    "# ============================================\n",
    "\n",
    "# Ensure correct ordering (important)\n",
    "analysis_dataset = (\n",
    "    analysis_dataset\n",
    "    .sort_values(\"game_date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 1: Next-game over/under outcome\n",
    "# shift(-1) pulls the NEXT game's result\n",
    "# --------------------------------------------\n",
    "analysis_dataset[\"next_over_flag\"] = (\n",
    "    analysis_dataset[\"over_flag\"].shift(-1)\n",
    ")\n",
    "\n",
    "# Drop final row (no next game exists)\n",
    "analysis_for_probs = analysis_dataset.dropna(subset=[\"next_over_flag\"])\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 2: Compute P(over | signed_streak)\n",
    "# Mean of binary variable = probability\n",
    "# --------------------------------------------\n",
    "prob_table = (\n",
    "    analysis_for_probs\n",
    "    .groupby(\"signed_streak\")[\"next_over_flag\"]\n",
    "    .agg(\n",
    "        prob_over=\"mean\",\n",
    "        n=\"count\"\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\"signed_streak\")\n",
    ")\n",
    "\n",
    "print(f\"\"\"overall prob_over = {analysis_dataset[\"over_flag\"].mean()}\"\"\")\n",
    "prob_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec282c0",
   "metadata": {},
   "source": [
    "The table above shows that...\n",
    "\n",
    "Below we only show streaks that have at least 5 occurrences to remove sparse streak events and show that the pattern still holds when we exclude these events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104492a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prob_table[prob_table[\"n\"] >= 5]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8be2a",
   "metadata": {},
   "source": [
    "While extreme streak lengths show volatile probabilities due to small sample sizes, the regression-to-mean effect persists for streak lengths with n ≥ 5, suggesting the result is not driven by sparse edge cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63250115",
   "metadata": {},
   "source": [
    "Now we'll perform a few validation tests to observe whether these findings are consistent under various conditions. Before we do that, we need to recreate the base dataset because we've already calculated rolling season averages and streak lengths under default conditions, but since we are going to be altering these conditions in the following tests, we will need to recompute values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"\"\"\n",
    "WITH teams AS(\n",
    "    SELECT \n",
    "        \"TEAM_ID\" AS team_id, \n",
    "        \"TEAM_ABBREVIATION\" AS team, \n",
    "        \"GAME_ID\" AS game_id,\n",
    "        \"GAME_DATE\" AS game_date, \n",
    "        \"MATCHUP\" AS matchup, \n",
    "        \"PTS\" AS pts,\n",
    "        AVG(\"PTS\") OVER (\n",
    "            PARTITION BY RIGHT(\"MATCHUP\", 3)\n",
    "            ORDER BY \"GAME_DATE\" ASC\n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING\n",
    "        ) AS opp_pts_allowed\n",
    "    FROM team_box_scores.league_gamelog t\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    t.game_id,\n",
    "    t.game_date,\n",
    "    p.\"personId\" AS player_id,\n",
    "    CONCAT_WS(' ', p.\"firstName\", p.\"familyName\") AS player_name,\n",
    "    p.\"teamId\" AS team_id,\n",
    "    RIGHT(t.matchup, 3) AS team,\n",
    "    p.points AS pts,\n",
    "    LEFT(t.matchup, 3) AS opp,\n",
    "    t.opp_pts_allowed,\n",
    "    t.matchup\n",
    "FROM teams t\n",
    "JOIN player_box_scores.player_boxscores p\n",
    "    ON p.\"teamId\" <> t.team_id\n",
    "        AND p.\"gameId\" = t.game_id\n",
    "ORDER BY player_id, game_date ASC\n",
    "\"\"\"\n",
    "\n",
    "analytic_base = pd.read_sql(base, engine)\n",
    "analytic_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632767c",
   "metadata": {},
   "source": [
    "Now we'll verify that this pattern holds on a smaller subsets of the dataset, starting with the first half of the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "murray = (\n",
    "    analytic_base[analytic_base[\"player_name\"] == \"Jamal Murray\"]\n",
    "    .sort_values(\"game_date\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Rolling season average points\n",
    "murray[\"szn_avg_pts\"] = (\n",
    "    murray[\"pts\"]\n",
    "    .expanding()\n",
    "    .mean()\n",
    "    .shift(1)\n",
    ")\n",
    "\n",
    "# Scoring deviations from season average\n",
    "murray[\"deviation\"] = murray[\"pts\"] - murray[\"szn_avg_pts\"]\n",
    "\n",
    "# Over/Under Flag\n",
    "murray[\"over_flag\"] = (murray[\"deviation\"] > 0).astype(int)\n",
    "\n",
    "# Streak ID - group together games from a streak\n",
    "murray[\"streak_id\"] = (\n",
    "    murray[\"over_flag\"]\n",
    "    .ne(murray[\"over_flag\"].shift())    # if change in over/under flag between consecutive games\n",
    "    .cumsum()                           # increment streak id \n",
    ")\n",
    "\n",
    "# Streak length\n",
    "murray[\"streak_length\"] = (\n",
    "    murray\n",
    "    .groupby(\"streak_id\")\n",
    "    .cumcount()\n",
    "    .add(1)\n",
    ")\n",
    "\n",
    "# Signed streak (positive = over, negative = under)\n",
    "murray[\"signed_streak\"] = (\n",
    "    murray[\"streak_length\"]\n",
    "    * murray[\"over_flag\"].replace({0: -1})\n",
    ")\n",
    "\n",
    "# Next game over/under flag\n",
    "murray[\"next_over_flag\"] = murray[\"over_flag\"].shift(-1)\n",
    "\n",
    "murray_early_season = murray[:34]\n",
    "murray_early_season = (\n",
    "    murray_early_season\n",
    "    .dropna(subset=[\"next_over_flag\"])\n",
    "    .groupby(\"signed_streak\")[\"next_over_flag\"]\n",
    "    .agg(prob_over=\"mean\", n=\"count\")\n",
    "    .reset_index()\n",
    ")\n",
    "murray_early_season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "murray_late_season = murray[34:]\n",
    "murray_late_season = (\n",
    "    murray_late_season\n",
    "    .dropna(subset=[\"next_over_flag\"])\n",
    "    .groupby(\"signed_streak\")[\"next_over_flag\"]\n",
    "    .agg(prob_over=\"mean\", n=\"count\")\n",
    "    .reset_index()\n",
    ")\n",
    "murray_late_season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a032a0",
   "metadata": {},
   "source": [
    "Now let's separate home and away games to see if the observed pattern still holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "murray_home = murray[murray[\"is_home\"] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd4b190",
   "metadata": {},
   "source": [
    "Now we'll see how probabilities shift when we change the definition of baseline performance to the rolling 10-game point average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310cf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dddf8ba",
   "metadata": {},
   "source": [
    "Now we'll see how probabilities shift when we only flag games that are +/- 2 points from baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cef4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe40947f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
